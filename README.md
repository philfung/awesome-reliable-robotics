# Awesome-Reliable-Robots
Collection of robotics research papers demonstrating reliability and robustness in real-world scenarios.  
Common themes include:
- reward learning from human feedback and interventions
- value / progress estimation.



| **Name** | **Date** | **Success Rate** | **Project** | **Paper** | **Code** |
| --- | --- | --- | --- | --- | --- |
| ReWiND: Language-Guided Rewards Teach Robot Policies without New Demonstrations | 05/2025 |  | https://rewind-reward.github.io/ | https://arxiv.org/abs/2505.10911 | N/A |
| RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation | 03/2025 | <img alt="RDT-1B" src="https://github.com/user-attachments/assets/aa8bbc19-f4d1-4006-aea3-65e34b30fd1b" />| https://rdt-robotics.github.io/rdt-robotics/ | https://arxiv.org/pdf/2410.07864 | https://github.com/thu-ml/RoboticsDiffusionTransformer |
| ConRFT: A Reinforced Fine-tuning Method for VLA Models via Consistency Policy | 02/2025 | average success rate of 96.3% |  | https://arxiv.org/pdf/2502.05450 | https://github.com/cccedric/conrft |
| Vision Language Models are In-Context Value Learner | 11/2024 | <img alt="GVL" src="https://github.com/user-attachments/assets/21541e78-91fd-478e-9de0-d491d3da8e44" />  | https://generative-value-learning.github.io/ | https://arxiv.org/pdf/2411.04549 | N/A |
| Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning | 10/2024 | <img alt="HIL-SERL" src="https://github.com/user-attachments/assets/56f35ef2-e297-4fd7-a4e0-362bf441c670" /> 100% success on a variety of tasks | https://hil-serl.github.io/ | https://hil-serl.github.io/static/hil-serl-paper.pdf | https://github.com/rail-berkeley/hil-serl |
| RLIF: INTERACTIVE IMITATION LEARNING AS REINFORCEMENT LEARNING | 03/2024 |<img alt="RLIF" src="https://github.com/user-attachments/assets/f101b109-e813-4deb-99b1-99f2e070e007" /> | https://rlif-page.github.io/ | https://arxiv.org/pdf/2311.12996 | https://github.com/pd-perry/RLIF |

