# Awesome Reliable Robots ðŸ¤–
Collection of robotics research papers demonstrating reliability and robustness in real-world scenarios.  
Common themes include:
- reward learning from human feedback and interventions
- value / progress estimation.

| **Name** | **Date** | **Real World Success Rate** | **Organization(s)** | **Project** | **Paper** | **Code** |
| --- | --- | --- | --- | --- | --- | --- |
| ReWiND: Language-Guided Rewards Teach Robot Policies without New Demonstrations | 05/2025 | **50% - 100%** success rate, **~5x** improvement over baseline <img alt="ReWIND" src="https://github.com/user-attachments/assets/ff5250b7-cbca-4747-aab2-7dcf257ce08b" />| USC, Amazon, KAIST | <a href="https://rewind-reward.github.io/" target="_blank">Link</a> |  <a href="https://arxiv.org/abs/2505.10911" target="_blank">Link</a> |  |
| Dynamism v1 (DYNA-1) Model: A Breakthrough in Performance and Production-Ready Embodied AI | 04/2025 | **99.4%** success rate over 24 hours in folding napkins with no intervention | Dyna Robotics | <a href="https://www.dyna.co/research)" target="_blank">Link</a> | | |
| RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation | 03/2025 | **56%** _improvement_ in success rates across tasks over baseline (ACT, VLA, Octo) <img alt="RDT-1B" src="https://github.com/user-attachments/assets/aa8bbc19-f4d1-4006-aea3-65e34b30fd1b" />| Tsinghua | <a href="https://rdt-robotics.github.io/rdt-robotics/" target="_blank">Link</a> |  <a href="https://arxiv.org/pdf/2410.07864" target="_blank">Link</a> | <a href="https://github.com/thu-ml/RoboticsDiffusionTransformer" target="_blank">Link</a> |
| ConRFT: A Reinforced Fine-tuning Method for VLA Models via Consistency Policy | 02/2025 | **96.3%** avg success rate across tasks <img alt="ConRFT" src="https://github.com/user-attachments/assets/15ddc8ba-59a6-448b-91db-3fefb212e8f7" />| Chinese Academy of Sciences | | <a href="https://arxiv.org/pdf/2502.05450" target="_blank">Link</a> | <a href="https://github.com/cccedric/conrft" target="_blank">Link</a> |
| Vision Language Models are In-Context Value Learner | 11/2024 | **15% - 90%** success rate, **0.46** avg _improvement_ (VOC) on scale -1.0 to 1.0 over DP (diffusion policy)<img alt="GVL" src="https://github.com/user-attachments/assets/21541e78-91fd-478e-9de0-d491d3da8e44" />  | Deepmind, UPenn, Stanford | <a href="https://generative-value-learning.github.io/" target="_blank">Link</a> | <a href="https://arxiv.org/pdf/2411.04549" target="_blank">Link</a> |  |
| Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning | 10/2024 | **100%** success rate on a variety of tasks <img alt="HIL-SERL" src="https://github.com/user-attachments/assets/56f35ef2-e297-4fd7-a4e0-362bf441c670" />  | UC Berkeley | <a href="https://hil-serl.github.io/" target="_blank">Link</a> | <a href="https://hil-serl.github.io/static/hil-serl-paper.pdf" target="_blank">Link</a> | <a href="https://github.com/rail-berkeley/hil-serl" target="_blank">Link</a> |
| RLIF: INTERACTIVE IMITATION LEARNING AS REINFORCEMENT LEARNING | 03/2024 | * **95%** success rate in cloth unfolding within 7 rounds * **100%** rate success in peg insertion within 6 rounds <img alt="RLIF" src="https://github.com/user-attachments/assets/f101b109-e813-4deb-99b1-99f2e070e007" /> | UC Berkeley | <a href="https://rlif-page.github.io/" target="_blank">Link</a> | <a href="https://arxiv.org/pdf/2311.12996" target="_blank">Link</a> | <a href="https://github.com/pd-perry/RLIF" target="_blank">Link</a> |


